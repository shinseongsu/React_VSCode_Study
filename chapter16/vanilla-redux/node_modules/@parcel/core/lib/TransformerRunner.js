"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _path = _interopRequireDefault(require("path"));

var _clone = _interopRequireDefault(require("clone"));

var _utils = require("@parcel/utils");

var _cache = _interopRequireDefault(require("@parcel/cache"));

var _fs = require("fs");

var _Dependency = _interopRequireDefault(require("./Dependency"));

var _Config = _interopRequireDefault(require("./Config"));

var _ResolverRunner = _interopRequireDefault(require("./ResolverRunner"));

var _ReporterRunner = require("./ReporterRunner");

var _Asset = require("./public/Asset");

var _Asset2 = _interopRequireDefault(require("./Asset"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

const BUFFER_LIMIT = 5000000; // 5mb

class TransformerRunner {
  constructor({
    config,
    options
  }) {
    _defineProperty(this, "options", void 0);

    _defineProperty(this, "config", void 0);

    _defineProperty(this, "resolverRunner", void 0);

    this.options = options;
    this.config = config;
    this.resolverRunner = new _ResolverRunner.default({
      config,
      options
    });
  }

  async transform(req) {
    (0, _ReporterRunner.report)({
      type: 'buildProgress',
      phase: 'transforming',
      request: req
    }); // If a cache entry matches, no need to transform.

    let cacheEntry;

    if (this.options.cache !== false && req.code == null) {
      cacheEntry = await _cache.default.get(reqCacheKey(req));
    }

    let {
      content,
      size,
      hash
    } = await summarizeRequest(req);

    if (cacheEntry && cacheEntry.hash === hash && (await checkCachedAssets(cacheEntry.assets))) {
      return cacheEntry;
    }

    let input = new _Asset2.default({
      // If the transformer request passed code rather than a filename,
      // use a hash as the base for the id to ensure it is unique.
      idBase: req.code ? hash : req.filePath,
      filePath: req.filePath,
      type: _path.default.extname(req.filePath).slice(1),
      ast: null,
      content,
      hash,
      env: req.env,
      stats: {
        time: 0,
        size
      },
      sideEffects: req.sideEffects
    });
    let pipeline = await this.config.getTransformers(req.filePath);
    let {
      assets,
      initialAssets
    } = await this.runPipeline({
      input,
      pipeline,
      cacheEntry
    });
    cacheEntry = {
      filePath: req.filePath,
      env: req.env,
      hash,
      assets,
      initialAssets
    };
    await Promise.all((0, _utils.unique)([...assets, ...(initialAssets || [])]).map(asset => asset.commit()));
    await _cache.default.set(reqCacheKey(req), cacheEntry);
    return cacheEntry;
  }

  async runPipeline({
    input,
    pipeline,
    originalPipeline = pipeline,
    cacheEntry,
    previousGenerate
  }) {
    // Run the first transformer in the pipeline.
    let inputType = input.type;
    let {
      results,
      generate,
      postProcess
    } = await this.runTransform(input, pipeline[0], previousGenerate);
    let assets = [];

    for (let result of results) {
      let asset = input.createChildAsset(result); // Check if any of the cached assets match the result.

      if (cacheEntry) {
        let cachedAssets = (cacheEntry.initialAssets || cacheEntry.assets).filter(child => child.hash && child.hash === asset.hash);

        if (cachedAssets.length > 0 && (await checkCachedAssets(cachedAssets))) {
          assets = assets.concat(cachedAssets);
          continue;
        }
      } // If the generated asset has a different type from the input, find the next pipeline


      let nextPipeline = originalPipeline;

      if (result.type !== inputType) {
        let nextFilePath = input.filePath.slice(0, -_path.default.extname(input.filePath).length) + '.' + result.type;
        nextPipeline = await this.config.getTransformers(nextFilePath);
      } // If the generated asset maps to the same pipeline as the input...


      if (isEqualPipeline(originalPipeline, nextPipeline)) {
        // If we have reached the last transform in the pipeline, then we are done.
        if (pipeline.length === 1) {
          assets.push((await finalize(asset, generate)));
        } else {
          // Recursively run the remaining transforms in the pipeline.
          let nextPipelineResult = await this.runPipeline({
            input: asset,
            originalPipeline,
            pipeline: pipeline.slice(1),
            previousGenerate: generate
          });
          assets = assets.concat(nextPipelineResult.assets);
        }
      } else {
        // Jump to a different pipeline for the generated asset.
        let nextPipelineResult = await this.runPipeline({
          input: asset,
          pipeline: nextPipeline,
          previousGenerate: generate
        });
        assets = assets.concat(nextPipelineResult.assets);
      }
    } // If the transformer has a postProcess function, execute that with the result of the pipeline.


    let finalAssets = await postProcess((0, _clone.default)(assets));
    return {
      assets: finalAssets || assets,
      initialAssets: finalAssets ? assets : null
    };
  }

  async runTransform(input, transformer, previousGenerate) {
    const resolve = async (from, to) => {
      return (await this.resolverRunner.resolve(new _Dependency.default({
        env: input.env,
        moduleSpecifier: to,
        sourcePath: from
      }))).filePath;
    }; // Load config for the transformer.


    let config = null;

    if (transformer.getConfig) {
      config = await transformer.getConfig({
        asset: new _Asset.MutableAsset(input),
        options: this.options,
        resolve
      });
    } // If an ast exists on the input, but we cannot reuse it,
    // use the previous transform to generate code that we can re-parse.


    if (input.ast && (!transformer.canReuseAST || !transformer.canReuseAST({
      ast: input.ast,
      options: this.options
    })) && previousGenerate) {
      let output = await previousGenerate(new _Asset.MutableAsset(input));
      input.content = output.code;
      input.ast = null;
    } // Parse if there is no AST available from a previous transform.


    if (!input.ast && transformer.parse) {
      input.ast = await transformer.parse({
        asset: new _Asset.MutableAsset(input),
        config,
        options: this.options,
        resolve
      });
    } // Transform.


    let results = normalizeAssets(( // $FlowFixMe
    await transformer.transform({
      asset: new _Asset.MutableAsset(input),
      config,
      options: this.options,
      resolve
    }))); // Create a generate function that can be called later to lazily generate

    let generate = async input => {
      if (transformer.generate) {
        return transformer.generate({
          asset: input,
          config,
          options: this.options,
          resolve
        });
      }

      throw new Error('Asset has an AST but no generate method is available on the transform');
    }; // Create a postProcess function that can be called later


    let postProcess = async assets => {
      let {
        postProcess
      } = transformer;

      if (postProcess) {
        let results = await postProcess({
          assets: assets.map(asset => new _Asset.MutableAsset(asset)),
          config,
          options: this.options,
          resolve
        });
        return Promise.all(results.map(result => input.createChildAsset(result)));
      }

      return null;
    };

    return {
      results,
      generate,
      postProcess
    };
  }

}

exports.default = TransformerRunner;

_defineProperty(TransformerRunner, "__exportSpecifier", "@parcel/core/lib/TransformerRunner.js");

function isEqualPipeline(a, b) {
  if (a === b) {
    return true;
  }

  if (a.length !== b.length) {
    return false;
  } // Plugins are cached, so we can just do a shallow comparison


  return a.every((p, i) => p === b[i]);
}

async function finalize(asset, generate) {
  if (asset.ast && generate) {
    let result = await generate(new _Asset.MutableAsset(asset));
    asset.content = result.code;
    asset.map = result.map;
  }

  return asset;
}

async function checkCachedAssets(assets) {
  let results = await Promise.all(assets.map(asset => checkConnectedFiles(asset.getConnectedFiles())));
  return results.every(Boolean);
}

async function checkConnectedFiles(files) {
  let hashes = await Promise.all(files.map(file => (0, _utils.md5FromFilePath)(file.filePath)));
  return files.every((file, index) => file.hash === hashes[index]);
}

function reqCacheKey(req) {
  return (0, _utils.md5FromString)(req.filePath + JSON.stringify(req.env));
}

async function summarizeRequest(req) {
  let code = req.code;
  let content;
  let hash;
  let size;

  if (code == null) {
    // As an optimization for the common case of source code, while we read in
    // data to compute its md5 and size, buffer its contents in memory.
    // This avoids reading the data now, and then again during transformation.
    // If it exceeds BUFFER_LIMIT, throw it out and replace it with a stream to
    // lazily read it at a later point.
    content = Buffer.from([]);
    size = 0;
    hash = await (0, _utils.md5FromReadableStream)((0, _fs.createReadStream)(req.filePath).pipe(new _utils.TapStream(buf => {
      size += buf.length;

      if (content instanceof Buffer) {
        if (size > BUFFER_LIMIT) {
          // if buffering this content would put this over BUFFER_LIMIT, replace
          // it with a stream
          content = (0, _fs.createReadStream)(req.filePath);
        } else {
          content = Buffer.concat([content, buf]);
        }
      }
    })));
  } else {
    content = code;
    hash = (0, _utils.md5FromString)(code);
    size = Buffer.from(code).length;
  }

  return {
    content,
    hash,
    size
  };
}

function normalizeAssets(results) {
  return results.map(result => {
    return result instanceof _Asset.MutableAsset ? {
      type: result.type,
      content: (0, _Asset.assetToInternalAsset)(result).content,
      ast: result.ast,
      // $FlowFixMe
      dependencies: result.getDependencies(),
      connectedFiles: result.getConnectedFiles(),
      // $FlowFixMe
      env: result.env,
      isIsolated: result.isIsolated,
      meta: result.meta
    } : result;
  });
}